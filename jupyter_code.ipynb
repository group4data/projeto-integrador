{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pyodbc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Iniciando com Spark\") \\\n",
    "    .config('spark.ui.port', '4051') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = \"Data/Clients\"\n",
    "\n",
    "transactions_in = \"Data/Transactions-in\"\n",
    "transactions_out = \"Data/Transactions-out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"nome\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"data_cadastro\", TimestampType(), True),\n",
    "        StructField(\"telefone\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "transactions_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"cliente_id\", IntegerType(), True),\n",
    "        StructField(\"valor\", DoubleType(), True),\n",
    "        StructField(\"data\", TimestampType(), True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_csv_to_df(spark, path, schema):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} não é um diretório válido.\")\n",
    "\n",
    "    list_paths_csv = glob.glob(os.path.join(path, '*.csv'))\n",
    "\n",
    "    if not list_paths_csv:\n",
    "        raise ValueError(f\"Não foram encontrados arquivos csv em {path}.\")\n",
    "\n",
    "    df = spark.read.csv(list_paths_csv, sep=';', schema=schema, inferSchema=True)\n",
    "\n",
    "    df = df.filter(~col('id').contains('id'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_empty_data(df):\n",
    "    for col_name in df.columns:\n",
    "        data_type = df.schema[col_name].dataType\n",
    "        if data_type == StringType():\n",
    "            count_empty = df.filter((col(col_name) == '') | isnull(col_name) | isnan(col_name) | (col(col_name).isNull())).count()\n",
    "            if count_empty != 0:\n",
    "                print(f\"Column '{col_name}' has {count_empty} empty/null/none/NaN values.\")\n",
    "                df = df.fillna({col_name: 'Não informado'})\n",
    "        elif data_type == IntegerType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: 0})\n",
    "        elif data_type == DoubleType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: 0.00})\n",
    "        elif data_type == TimestampType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: '1900-01-01 00:00:00'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correcting_data(df):\n",
    "    df = df.withColumn(\"valor\", round(col(\"valor\"), 2))\n",
    "    df = df.withColumn('valor', expr('abs(valor)'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_state_column(df):\n",
    "    # Cria coluna do DDD a partir da coluna Telefone\n",
    "    df = df.withColumn('DDD', split(df['telefone'], r'[()]+').getItem(1))\n",
    "    # Substitui os DDDs pelo Estado correspondente\n",
    "    df = df.withColumn('estado', when(col('DDD') == '20', 'Paraíba')\n",
    "                        .when(col('DDD') == '21', 'Rio de Janeiro')\n",
    "                        .when(col('DDD') == '22', 'Mato Grosso')\n",
    "                        .when(col('DDD') == '23', 'Pernambuco')\n",
    "                        .when(col('DDD') == '24', 'Rio de Janeiro')\n",
    "                        .when(col('DDD') == '25', 'Bahia')\n",
    "                        .when(col('DDD') == '26', 'Minas Gerais')\n",
    "                        .when(col('DDD') == '27', 'Espírito Santo')\n",
    "                        .when(col('DDD') == '28', 'Roraima')\n",
    "                        .when(col('DDD') == '29', 'São Paulo')\n",
    "                        .when(col('DDD') == '30', 'Maranhão')\n",
    "                        .otherwise('Inválido'))\n",
    "    # Apagando coluna DDD\n",
    "    df = df.drop('DDD')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_names(df):\n",
    "    # Separando os nomes dos sobrenomes\n",
    "    df = df.withColumn(\"nome_split\", split(df.nome, \" \"))\n",
    "    df = df.withColumn(\"nome\", df.nome_split[0])\n",
    "    df = df.withColumn(\"sobrenome1\", df.nome_split[1])\n",
    "    df = df.withColumn(\"sobrenome2\", df.nome_split[2])\n",
    "    df = df.withColumn(\"sobrenome3\", df.nome_split[3])\n",
    "    df = df.withColumn(\"sobrenome4\", df.nome_split[4])\n",
    "    df = df.withColumn(\"sobrenome5\", df.nome_split[5])\n",
    "    df = df.withColumn(\"sobrenome6\", df.nome_split[6])\n",
    "    df = df.withColumn(\"sobrenome\", concat_ws(\" \", \"sobrenome1\", \"sobrenome2\", \"sobrenome3\", \"sobrenome4\", \"sobrenome5\", \"sobrenome6\"))\n",
    "    df = df.drop(\"nome_split\", \"sobrenome1\", \"sobrenome2\", \"sobrenome3\", \"sobrenome4\", \"sobrenome5\", \"sobrenome6\")\n",
    "    # Colocando primeira letra de cada nome Maiúscula\n",
    "    df = df.withColumn(\"nome\", initcap(df.nome))\n",
    "    df = df.withColumn(\"sobrenome\", initcap(df.sobrenome))\n",
    "    # Substituindo linhas vazias por Não Informado\n",
    "    df = df.withColumn(\"sobrenome\", when(df.sobrenome == \"\", \"Não informado\").otherwise(df.sobrenome))\n",
    "    # Ordenando as colunas\n",
    "    df = df.select(\"id\", \"nome\", \"sobrenome\", \"email\", \"data_cadastro\", \"telefone\", \"estado\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_client_id_existence(spark, df_transactions, df_clients):\n",
    "    df_ids_transactions = df_transactions.select(col('cliente_id'))\n",
    "    df_ids_clients = df_clients.select(col('id'))\n",
    "    df_new_clients = df_ids_transactions.join(df_ids_clients, df_ids_transactions.cliente_id == df_ids_clients.id, \"leftanti\")\n",
    "    df_new_clients = df_new_clients.distinct()\n",
    "    df_new_clients = df_new_clients.withColumnRenamed(\"cliente_id\", \"id\")\n",
    "    df_new_clients = df_new_clients.withColumn('nome', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('sobrenome', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('email', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('data_cadastro', lit('1900-01-01 00:00:00').cast('timestamp'))\n",
    "    df_new_clients = df_new_clients.withColumn('telefone', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('estado', lit('Não localizado'))\n",
    "    df_clients = df_clients.unionAll(df_new_clients)\n",
    "    return df_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_df_in_out(df_transactions_in, df_transactions_out):\n",
    "    df_transactions_in = df_transactions_in.withColumn('tipo_transacao', lit('IN'))\n",
    "    df_transactions_out = df_transactions_out.withColumn('tipo_transacao', lit('OUT'))\n",
    "    df_transactions = df_transactions_in.unionAll(df_transactions_out)\n",
    "    return df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_database():\n",
    "    load_dotenv()\n",
    "    server_name = os.environ[\"server_name\"]\n",
    "    database_name = os.environ[\"database_name\"]\n",
    "    username = os.environ[\"username\"]\n",
    "    password = os.environ[\"password\"]\n",
    "\n",
    "    connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};Server=tcp:{server_name},1433;Database={database_name};Uid={username};Pwd={password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "    return pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_clients(conn, df):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'clientes'\")\n",
    "    if cursor.fetchone()[0] == 0:\n",
    "        create_table_query = '''CREATE TABLE clientes (\n",
    "                                    id INTEGER PRIMARY KEY,\n",
    "                                    nome VARCHAR(255),\n",
    "                                    sobrenome VARCHAR(255),\n",
    "                                    email VARCHAR(255),\n",
    "                                    data_hora_cadastro DATETIME,\n",
    "                                    telefone VARCHAR(255),\n",
    "                                    estado VARCHAR(255)\n",
    "                                    );'''\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Tabela clientes criada com sucesso!\")\n",
    "        insert_df_into_db(conn, df, \"clientes\")\n",
    "    else:\n",
    "        print(\"A tabela clientes já está no banco de dados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_df_into_db(conn, df, table_name):\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Inserindo os dados na tabela...\")\n",
    "    try:\n",
    "        columns = \",\".join(df.columns)\n",
    "        placeholders = \",\".join(\"?\" for _ in df.columns)\n",
    "        df = df.rdd.collect()\n",
    "\n",
    "        for values in df:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\", values)\n",
    "            cursor.commit()\n",
    "        print(\"Os dados foram inseridos com sucesso na tabela.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao inserir os dados na tabela: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_transactions(conn, df, name_table):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{name_table}'\")\n",
    "    if cursor.fetchone()[0] == 0:\n",
    "        create_table_query = f\"CREATE TABLE {name_table} (\\\n",
    "                                id INTEGER PRIMARY KEY,\\\n",
    "                                cliente_id INTEGER REFERENCES clientes (id),\\\n",
    "                                valor DECIMAL(10,2),\\\n",
    "                                data_hora DATETIME,\\\n",
    "                            );\"\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(f\"Tabela {name_table} criada com sucesso!\")\n",
    "        insert_df_into_db(conn, df, name_table)\n",
    "    else: \n",
    "        print(f\"A tabela {name_table} já está no banco de dados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Transformando os arquivos CSVs em data frames...\")\n",
    "    df_clients = transform_csv_to_df(spark, clients, clients_schema)\n",
    "    df_transactions_in = transform_csv_to_df(spark, transactions_in, transactions_schema)\n",
    "    df_transactions_out = transform_csv_to_df(spark, transactions_out , transactions_schema)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Verificando se há dados não informados nas colunas dos DataFrames...\")\n",
    "    verify_empty_data(df_clients)\n",
    "    verify_empty_data(df_transactions_in)\n",
    "    verify_empty_data(df_transactions_out)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Corrigindo os dados da coluna valor dos DataFrames de transações...\")\n",
    "    df_transactions_in = correcting_data(df_transactions_in)\n",
    "    df_transactions_out = correcting_data(df_transactions_out)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Formatando o DataFrame de clientes...\")\n",
    "    df_clients = add_state_column(df_clients)\n",
    "    df_clients = format_names(df_clients)\n",
    "    df_clients = verify_client_id_existence(spark, df_transactions_in, df_clients)\n",
    "    df_clients = verify_client_id_existence(spark, df_transactions_out, df_clients)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Unindo os dados das transações em um único DataFrame...\")\n",
    "    dt_transactions = union_df_in_out(df_transactions_in, df_transactions_out)\n",
    "    print(\"OK\")\n",
    "      \n",
    "    print(\"-\" * 30)\n",
    "    print(\"Transações in\")\n",
    "    df_transactions_in.show()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Transações out\")\n",
    "    df_transactions_out.show()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Dados dos clientes\")\n",
    "    df_clients.show()\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        print(\"Conectando com o banco de dados...\")\n",
    "        conn = connection_database()\n",
    "    except Exception:\n",
    "        print(\"Não foi possivel se conectar com o banco de dados!\")\n",
    "    else:\n",
    "        print(\"Criando tabela de clientes no banco de dados!\")\n",
    "        create_table_clients(conn, df_clients)\n",
    "        \n",
    "        df_transactions_in = df_transactions_in.join(df_clients, df_clients.id == df_transactions_in.cliente_id, \"leftsemi\")\n",
    "        df_transactions_out = df_transactions_out.join(df_clients, df_clients.id == df_transactions_out.cliente_id, \"leftsemi\")\n",
    "\n",
    "        print(\"Criando as tabelas de transações no banco de dados!\")\n",
    "        create_table_transactions(conn, df_transactions_in, \"transactions_in\")\n",
    "        create_table_transactions(conn, df_transactions_out, \"transactions_out\")\n",
    "    '''\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu o seguinte erro: {e}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
