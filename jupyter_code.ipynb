{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pyodbc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando o Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Iniciando com Spark\") \\\n",
    "    .config('spark.ui.port', '4051') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis para os diretórios dos dados brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = \"Data/Clients\"\n",
    "\n",
    "transactions_in = \"Data/Transactions-in\"\n",
    "transactions_out = \"Data/Transactions-out\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis para os schemas dos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"nome\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"data_cadastro\", TimestampType(), True),\n",
    "        StructField(\"telefone\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "transactions_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"cliente_id\", IntegerType(), True),\n",
    "        StructField(\"valor\", DoubleType(), True),\n",
    "        StructField(\"data\", TimestampType(), True),\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para carregar os arquivos .csv convertendo-os em DataFrames usando Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_csv_to_df(spark, path, schema):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} não é um diretório válido.\")\n",
    "\n",
    "    list_paths_csv = glob.glob(os.path.join(path, '*.csv'))\n",
    "\n",
    "    if not list_paths_csv:\n",
    "        raise ValueError(f\"Não foram encontrados arquivos csv em {path}.\")\n",
    "\n",
    "    df = spark.read.csv(list_paths_csv, sep=';', schema=schema, inferSchema=True)\n",
    "\n",
    "    df = df.filter(~col('id').contains('id'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para verificar se há dados nulos ou não informados nos DataFrames, caso sim, os dados são preenchidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_empty_data(df):\n",
    "    for col_name in df.columns:\n",
    "        data_type = df.schema[col_name].dataType\n",
    "        if data_type == StringType():\n",
    "            count_empty = df.filter((col(col_name) == '') | isnull(col_name) | isnan(col_name) | (col(col_name).isNull())).count()\n",
    "            if count_empty != 0:\n",
    "                print(f\"Column '{col_name}' has {count_empty} empty/null/none/NaN values.\")\n",
    "                df = df.fillna({col_name: 'Não informado'})\n",
    "        elif data_type == IntegerType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: 0})\n",
    "        elif data_type == DoubleType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: 0.00})\n",
    "        elif data_type == TimestampType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: '1900-01-01 00:00:00'})\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para padronizar os dados da coluna valor dos DataFrames transactions_in e transactions_out corrigindo-os para que todos tenham duas casas decimais e valor absoluto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correcting_data(df):\n",
    "    df = df.withColumn(\"valor\", round(col(\"valor\"), 2))\n",
    "    df = df.withColumn('valor', expr('abs(valor)'))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para criar a coluna estado no DataFrame clients a partir do número do DDD extraído da coluna telefone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_state_column(df):\n",
    "    df = df.withColumn('DDD', split(df['telefone'], r'[()]+').getItem(1))\n",
    "    df = df.withColumn('estado', when(col('DDD') == '20', 'Paraíba')\n",
    "                        .when(col('DDD') == '21', 'Rio de Janeiro')\n",
    "                        .when(col('DDD') == '22', 'Mato Grosso')\n",
    "                        .when(col('DDD') == '23', 'Pernambuco')\n",
    "                        .when(col('DDD') == '24', 'Rio de Janeiro')\n",
    "                        .when(col('DDD') == '25', 'Bahia')\n",
    "                        .when(col('DDD') == '26', 'Minas Gerais')\n",
    "                        .when(col('DDD') == '27', 'Espírito Santo')\n",
    "                        .when(col('DDD') == '28', 'Roraima')\n",
    "                        .when(col('DDD') == '29', 'São Paulo')\n",
    "                        .when(col('DDD') == '30', 'Maranhão')\n",
    "                        .otherwise('Inválido'))\n",
    "    df = df.drop('DDD')\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para formatar os nomes dos clientes, dividindo em duas colunas denominadas nome e sobrenome, verificando os que não possuem sobrenome e preenchendo com 'Não informado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_names(df):\n",
    "    df = df.withColumn(\"nome_split\", split(df.nome, \" \"))\n",
    "    df = df.withColumn(\"nome\", df.nome_split[0])\n",
    "    df = df.withColumn(\"sobrenome1\", df.nome_split[1])\n",
    "    df = df.withColumn(\"sobrenome2\", df.nome_split[2])\n",
    "    df = df.withColumn(\"sobrenome3\", df.nome_split[3])\n",
    "    df = df.withColumn(\"sobrenome4\", df.nome_split[4])\n",
    "    df = df.withColumn(\"sobrenome5\", df.nome_split[5])\n",
    "    df = df.withColumn(\"sobrenome6\", df.nome_split[6])\n",
    "    df = df.withColumn(\"sobrenome\", concat_ws(\" \", \"sobrenome1\", \"sobrenome2\", \"sobrenome3\", \"sobrenome4\", \"sobrenome5\", \"sobrenome6\"))\n",
    "    df = df.drop(\"nome_split\", \"sobrenome1\", \"sobrenome2\", \"sobrenome3\", \"sobrenome4\", \"sobrenome5\", \"sobrenome6\")\n",
    "    df = df.withColumn(\"nome\", initcap(df.nome))\n",
    "    df = df.withColumn(\"sobrenome\", initcap(df.sobrenome))\n",
    "    df = df.withColumn(\"sobrenome\", when(df.sobrenome == \"\", \"Não informado\").otherwise(df.sobrenome))\n",
    "    df = df.select(\"id\", \"nome\", \"sobrenome\", \"email\", \"data_cadastro\", \"telefone\", \"estado\")\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para verificar se todos ids de clientes existentes nos DataFrames de transactions_in e transactions_out correspondem a um id no DataFrame clients e caso não exista, o id é adicionado no DataFrame clients preenchendo as demais colunas com 'Não localizado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_client_id_existence(spark, df_transactions, df_clients):\n",
    "    df_ids_transactions = df_transactions.select(col('cliente_id'))\n",
    "    df_ids_clients = df_clients.select(col('id'))\n",
    "    df_new_clients = df_ids_transactions.join(df_ids_clients, df_ids_transactions.cliente_id == df_ids_clients.id, \"leftanti\")\n",
    "    df_new_clients = df_new_clients.distinct()\n",
    "    df_new_clients = df_new_clients.withColumnRenamed(\"cliente_id\", \"id\")\n",
    "    df_new_clients = df_new_clients.withColumn('nome', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('sobrenome', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('email', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('data_cadastro', lit('1900-01-01 00:00:00').cast('timestamp'))\n",
    "    df_new_clients = df_new_clients.withColumn('telefone', lit('Não localizado'))\n",
    "    df_new_clients = df_new_clients.withColumn('estado', lit('Não localizado'))\n",
    "    df_clients = df_clients.unionAll(df_new_clients)\n",
    "    return df_clients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para renomear as colunas do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamed_column(df, previous_column, new_column):\n",
    "     return df.withColumnRenamed(previous_column, new_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para realizar a conexão com o banco de dados SQL Server na Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_database():\n",
    "    load_dotenv()\n",
    "    server_name = os.environ[\"server_name\"]\n",
    "    database_name = os.environ[\"database_name\"]\n",
    "    username = os.environ[\"username\"]\n",
    "    password = os.environ[\"password\"]\n",
    "\n",
    "    connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};\\\n",
    "        Server=tcp:{server_name},1433;\\\n",
    "        Database={database_name};\\\n",
    "        Uid={username};\\\n",
    "        Pwd={password};\\\n",
    "        Encrypt=yes;\\\n",
    "        TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "    return pyodbc.connect(connection_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para criar a tabela CLIENTS no banco de dados SQL Server na Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_clients(conn, df):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'clientes'\")\n",
    "    if cursor.fetchone()[0] == 0:\n",
    "        create_table_query = f\"CREATE TABLE clientes (\\\n",
    "                                    id INTEGER PRIMARY KEY,\\\n",
    "                                    nome VARCHAR(255),\\\n",
    "                                    sobrenome VARCHAR(255),\\\n",
    "                                    email VARCHAR(255),\\\n",
    "                                    data_hora_cadastro DATETIME,\\\n",
    "                                    telefone VARCHAR(255),\\\n",
    "                                    estado VARCHAR(255)\\\n",
    "                                    );\"\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Tabela clientes criada com sucesso!\")\n",
    "    else:\n",
    "        print(\"A tabela clientes já está no banco de dados!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para criar as tabelas TRANSACTIONS_IN e TRANSACTIONS_OUT no banco de dados SQL Server na Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_transactions(conn, df, name_table):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{name_table}'\")\n",
    "    if cursor.fetchone()[0] == 0:\n",
    "        create_table_query = f\"CREATE TABLE {name_table} (\\\n",
    "                                id INTEGER PRIMARY KEY,\\\n",
    "                                cliente_id INTEGER REFERENCES clientes (id),\\\n",
    "                                valor DECIMAL(10,2),\\\n",
    "                                data_hora DATETIME,\\\n",
    "                            );\"\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(f\"Tabela {name_table} criada com sucesso!\")\n",
    "    else: \n",
    "        print(f\"A tabela {name_table} já está no banco de dados!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para inserir os dataframes nas tabelas já existentes no banco de dados SQL Server na Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_df_into_db(conn, df, name_table):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        columns = \",\".join(df.columns)      \n",
    "        placeholders = \",\".join(\"?\" for _ in df.columns) \n",
    "        df = df.rdd.collect()\n",
    "\n",
    "        for values in df:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f\"INSERT INTO {name_table} ({columns}) VALUES ({placeholders})\", values)\n",
    "            cursor.commit()\n",
    "        print(\"Os dados foram inseridos com sucesso na tabela.\")\n",
    "    except pyodbc.IntegrityError:\n",
    "        print(f\"Os dados já existem no banco de dados!\")\n",
    "        conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao inserir os dados na tabela: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Transformando os arquivos CSVs em data frames...\")\n",
    "    df_clients = transform_csv_to_df(spark, clients, clients_schema)\n",
    "    df_transactions_in = transform_csv_to_df(spark, transactions_in, transactions_schema)\n",
    "    df_transactions_out = transform_csv_to_df(spark, transactions_out , transactions_schema)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Verificando se há dados não informados nas colunas dos DataFrames...\")\n",
    "    df_clients = verify_empty_data(df_clients)\n",
    "    df_transactions_in = verify_empty_data(df_transactions_in)\n",
    "    df_transactions_out = verify_empty_data(df_transactions_out)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Corrigindo os dados da coluna valor dos DataFrames de transações...\")\n",
    "    df_transactions_in = correcting_data(df_transactions_in)\n",
    "    df_transactions_out = correcting_data(df_transactions_out)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Formatando o DataFrame de clientes...\")\n",
    "    df_clients = add_state_column(df_clients)\n",
    "    df_clients = format_names(df_clients)\n",
    "    df_clients = verify_client_id_existence(spark, df_transactions_in, df_clients)\n",
    "    df_clients = verify_client_id_existence(spark, df_transactions_out, df_clients)\n",
    "    print(\"OK\")\n",
    "    \n",
    "    print(\"Alterando o nome das colunas de data e hora dos DataFrames...\")\n",
    "    df_clients = renamed_column(df_clients,\"data_cadastro\", \"data_hora_cadastro\")\n",
    "    df_transactions_in = renamed_column(df_transactions_in, \"data\", \"data_hora\")\n",
    "    df_transactions_out = renamed_column(df_transactions_out, \"data\", \"data_hora\")\n",
    "    print(\"OK\")\n",
    "\n",
    "    try:\n",
    "        print(\"Conectando com o banco de dados...\")\n",
    "        conn = connection_database()\n",
    "        print(\"OK\")\n",
    "    except Exception as e:\n",
    "        print(f\"Não foi possivel se conectar com o banco de dados! Por causa do seguinte erro: {e}\")\n",
    "    else:\n",
    "        print(\"\\nCriando tabela de clientes no banco de dados!\")\n",
    "        create_table_clients(conn, df_clients)\n",
    "        \n",
    "        print(\"\\nInserindo dados na tabela...\")\n",
    "        insert_df_into_db(conn, df_clients, \"clientes\")\n",
    "            \n",
    "        print(\"\\nCriando a tabela de transações in no banco de dados!\")\n",
    "        create_table_transactions(conn, df_transactions_in, \"transactions_in\")\n",
    "\n",
    "        print(\"\\nInserindo dados na tabela...\")\n",
    "        insert_df_into_db(conn, df_transactions_in, \"transactions_in\")\n",
    "    \n",
    "        print(\"\\nCriando a tabela de transações out no banco de dados!\")\n",
    "        create_table_transactions(conn, df_transactions_out, \"transactions_out\")\n",
    "\n",
    "        print(\"\\nInserindo dados na tabela...\")\n",
    "        insert_df_into_db(conn, df_transactions_out, \"transactions_out\")\n",
    "       \n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Transações in\")\n",
    "    df_transactions_in.show()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Transações out\")\n",
    "    df_transactions_out.show()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Dados dos clientes\")\n",
    "    df_clients.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu o seguinte erro: {e}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
