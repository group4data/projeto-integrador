{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pyodbc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Starting Spark Session\") \\\n",
    "    .config('spark.ui.port', '4051') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables for raw data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = \"Data/Clients\"\n",
    "\n",
    "transactions_in = \"Data/Transactions-in\"\n",
    "transactions_out = \"Data/Transactions-out\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables for DataFrames schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"nome\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"data_cadastro\", TimestampType(), True),\n",
    "        StructField(\"telefone\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "transactions_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"cliente_id\", IntegerType(), True),\n",
    "        StructField(\"valor\", DoubleType(), True),\n",
    "        StructField(\"data\", TimestampType(), True),\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load .csv files converting them into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_csv_to_df(spark, path, schema):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} is not a valid directory.\")\n",
    "\n",
    "    list_paths_csv = glob.glob(os.path.join(path, '*.csv'))\n",
    "\n",
    "    if not list_paths_csv:\n",
    "        raise ValueError(f\"No csv files found in {path}.\")\n",
    "\n",
    "    df = spark.read.csv(list_paths_csv, sep=';', schema=schema, inferSchema=True)\n",
    "\n",
    "    df = df.filter(~col('id').contains('id'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check if there is null or missing data in the DataFrames, if so, the data is filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_empty_data(df):\n",
    "    for col_name in df.columns:\n",
    "        data_type = df.schema[col_name].dataType\n",
    "        if data_type == StringType():\n",
    "            count_empty = df.filter((col(col_name) == '') | isnull(col_name) | isnan(col_name) | (col(col_name).isNull())).count()\n",
    "            if count_empty != 0:\n",
    "                print(f\"Column '{col_name}' has {count_empty} empty/null/none/NaN values.\")\n",
    "                df = df.fillna({col_name: 'Not Informed'})\n",
    "        elif data_type == IntegerType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: 0})\n",
    "        elif data_type == DoubleType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: 0.00})\n",
    "        elif data_type == TimestampType():\n",
    "            count_null = df.filter(col(col_name).isNull()).count()\n",
    "            if count_null != 0:\n",
    "                print(f\"Column '{col_name}' has {count_null} null values.\")\n",
    "                df = df.fillna({col_name: '1900-01-01 00:00:00'})\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to standardize the value column data of the transactions_in and transactions_out DataFrames, correcting them so that they all have two decimal places and an absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correcting_data(df):\n",
    "    df = df.withColumn(\"value\", round(col(\"value\"), 2))\n",
    "    df = df.withColumn(\"value\", expr('abs(value)'))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create the state column in the DataFrame clients from the DDD number extracted from the phone_number column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_state_column(df):\n",
    "    df = df.withColumn('DDD', split(df['phone_number'], r'[()]+').getItem(1))\n",
    "    df = df.withColumn('state', when(col('DDD') == '20', 'Paraíba')\n",
    "                        .when(col('DDD') == '21', 'Rio de Janeiro')\n",
    "                        .when(col('DDD') == '22', 'Mato Grosso')\n",
    "                        .when(col('DDD') == '23', 'Pernambuco')\n",
    "                        .when(col('DDD') == '24', 'Rio de Janeiro')\n",
    "                        .when(col('DDD') == '25', 'Bahia')\n",
    "                        .when(col('DDD') == '26', 'Minas Gerais')\n",
    "                        .when(col('DDD') == '27', 'Espírito Santo')\n",
    "                        .when(col('DDD') == '28', 'Roraima')\n",
    "                        .when(col('DDD') == '29', 'São Paulo')\n",
    "                        .when(col('DDD') == '30', 'Maranhão')\n",
    "                        .otherwise('Invalid'))\n",
    "    df = df.drop('DDD')\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to format customer names, dividing into two columns called first and last name, checking those that do not have a last name and filling in with 'Not informed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_names(df):\n",
    "    df = df.withColumn(\"name_split\", split(df.name, \" \"))\n",
    "    df = df.withColumn(\"name\", df.name_split[0])\n",
    "    df = df.withColumn(\"last_name1\", df.name_split[1])\n",
    "    df = df.withColumn(\"last_name2\", df.name_split[2])\n",
    "    df = df.withColumn(\"last_name3\", df.name_split[3])\n",
    "    df = df.withColumn(\"last_name4\", df.name_split[4])\n",
    "    df = df.withColumn(\"last_name5\", df.name_split[5])\n",
    "    df = df.withColumn(\"last_name6\", df.name_split[6])\n",
    "    df = df.withColumn(\"last_name\", concat_ws(\" \", \"last_name1\", \"last_name2\", \"last_name3\", \"last_name4\", \"last_name5\", \"last_name6\"))\n",
    "    df = df.drop(\"name_split\", \"last_name1\", \"last_name2\", \"last_name3\", \"last_name4\", \"last_name5\", \"last_name6\")\n",
    "    df = df.withColumn(\"name\", initcap(df.name))\n",
    "    df = df.withColumn(\"last_name\", initcap(df.last_name))\n",
    "    df = df.withColumn(\"last_name\", when(df.last_name == \"\", \"Not Informed\").otherwise(df.last_name))\n",
    "    df = df.select(\"id\", \"name\", \"last_name\", \"email\", \"date_time_register\", \"phone_number\", \"state\")\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check if all existing customer ids in the transactions_in and transactions_out DataFrames correspond to an id in the clients DataFrame and if it does not exist, the id is added to the clients DataFrame filling the other columns with 'Not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_client_id_existence(df_transactions, df_clients):\n",
    "    df_ids_transactions = df_transactions.select(col('client_id'))\n",
    "    df_ids_clients = df_clients.select(col('id'))\n",
    "    df_new_clients = df_ids_transactions.join(df_ids_clients, df_ids_transactions.client_id == df_ids_clients.id, \"leftanti\")\n",
    "    df_new_clients = df_new_clients.distinct()\n",
    "    df_new_clients = df_new_clients.withColumnRenamed(\"client_id\", \"id\")\n",
    "    df_new_clients = df_new_clients.withColumn('name', lit('Not found'))\n",
    "    df_new_clients = df_new_clients.withColumn('last_name', lit('Not found'))\n",
    "    df_new_clients = df_new_clients.withColumn('email', lit('Not found'))\n",
    "    df_new_clients = df_new_clients.withColumn('date_time_register', lit('1900-01-01 00:00:00').cast('timestamp'))\n",
    "    df_new_clients = df_new_clients.withColumn('phone_number', lit('Not found'))\n",
    "    df_new_clients = df_new_clients.withColumn('state', lit('Not found'))\n",
    "    df_clients = df_clients.unionAll(df_new_clients)\n",
    "    return df_clients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to rename DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamed_column(df, previous_column, new_column):\n",
    "     return df.withColumnRenamed(previous_column, new_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to connect to SQL Server database on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_database():\n",
    "    load_dotenv()\n",
    "    server_name = os.environ[\"server_name\"]\n",
    "    database_name = os.environ[\"database_name\"]\n",
    "    username = os.environ[\"username\"]\n",
    "    password = os.environ[\"password\"]\n",
    "\n",
    "    connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};\\\n",
    "        Server=tcp:{server_name},1433;\\\n",
    "        Database={database_name};\\\n",
    "        Uid={username};\\\n",
    "        Pwd={password};\\\n",
    "        Encrypt=yes;\\\n",
    "        TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "    return pyodbc.connect(connection_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create the clients table in SQL Server database on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_clients(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'clients'\")\n",
    "    if cursor.fetchone()[0] == 0:\n",
    "        create_table_query = f\"CREATE TABLE clients (\\\n",
    "                                    id INTEGER PRIMARY KEY,\\\n",
    "                                    name VARCHAR(255),\\\n",
    "                                    last_name VARCHAR(255),\\\n",
    "                                    email VARCHAR(255),\\\n",
    "                                    date_time_register DATETIME,\\\n",
    "                                    phone_number VARCHAR(255),\\\n",
    "                                    state VARCHAR(255)\\\n",
    "                                    );\"\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"clients table successfully created!\")\n",
    "    else:\n",
    "        print(\"clients table is already in the database!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create the transactions_in and transactions_out tables in SQL Server database on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_transactions(conn, name_table):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = '{name_table}'\")\n",
    "    if cursor.fetchone()[0] == 0:\n",
    "        create_table_query = f\"CREATE TABLE {name_table} (\\\n",
    "                                id INTEGER PRIMARY KEY,\\\n",
    "                                client_id INTEGER REFERENCES clients (id),\\\n",
    "                                value DECIMAL(10,2),\\\n",
    "                                date_time DATETIME,\\\n",
    "                            );\"\n",
    "\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(f\"{name_table} table successfully created!\")\n",
    "    else: \n",
    "        print(f\"{name_table} table is already in the database!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to insert DataFrames into existing tables in SQL Server database on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_df_into_db(conn, df, name_table):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        columns = \",\".join(df.columns)      \n",
    "        placeholders = \",\".join(\"?\" for _ in df.columns) \n",
    "        df = df.rdd.collect()\n",
    "\n",
    "        for values in df:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f\"INSERT INTO {name_table} ({columns}) VALUES ({placeholders})\", values)\n",
    "            cursor.commit()\n",
    "        print(\"The data has been successfully inserted into the table.\")\n",
    "    except pyodbc.IntegrityError:\n",
    "        print(f\"This data already exists in the database!\")\n",
    "        conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while inserting data into the table: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main script of the application that uses the previously defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Transforming CSV files into DataFrame....\")\n",
    "    df_clients = transform_csv_to_df(spark, clients, clients_schema)\n",
    "    df_transactions_in = transform_csv_to_df(spark, transactions_in, transactions_schema)\n",
    "    df_transactions_out = transform_csv_to_df(spark, transactions_out , transactions_schema)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Renaming DataFrames columns...\")\n",
    "    df_clients = renamed_column(df_clients,\"nome\", \"name\")\n",
    "    df_clients = renamed_column(df_clients,\"data_cadastro\", \"date_time_register\")\n",
    "    df_clients = renamed_column(df_clients,\"telefone\", \"phone_number\")\n",
    "\n",
    "    df_transactions_in = renamed_column(df_transactions_in, \"cliente_id\", \"client_id\")\n",
    "    df_transactions_in = renamed_column(df_transactions_in, \"valor\", \"value\")\n",
    "    df_transactions_in = renamed_column(df_transactions_in, \"data\", \"date_time\")\n",
    "\n",
    "    df_transactions_out = renamed_column(df_transactions_out, \"cliente_id\", \"client_id\")\n",
    "    df_transactions_out = renamed_column(df_transactions_out, \"valor\", \"value\")\n",
    "    df_transactions_out = renamed_column(df_transactions_out, \"data\", \"date_time\")\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Checking for missing data in DataFrames columns...\")\n",
    "    df_clients = verify_empty_data(df_clients)\n",
    "    df_transactions_in = verify_empty_data(df_transactions_in)\n",
    "    df_transactions_out = verify_empty_data(df_transactions_out)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Correcting data in the value column of transactions DataFrames..\")\n",
    "    df_transactions_in = correcting_data(df_transactions_in)\n",
    "    df_transactions_out = correcting_data(df_transactions_out)\n",
    "    print(\"OK\")\n",
    "\n",
    "    print(\"Formatting the clients DataFrame...\")\n",
    "    df_clients = add_state_column(df_clients)\n",
    "    df_clients = format_names(df_clients)\n",
    "    df_clients = verify_client_id_existence(df_transactions_in, df_clients)\n",
    "    df_clients = verify_client_id_existence(df_transactions_out, df_clients)\n",
    "    print(\"OK\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Connecting to the database...\")\n",
    "        conn = connection_database()\n",
    "        print(\"OK\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to connect to the database! The following error occurred: {e}\")\n",
    "    else:\n",
    "        print(\"\\nCreating clients table in database...\")\n",
    "        create_table_clients(conn)\n",
    "        \n",
    "        print(\"\\nInserting data into the table...\")\n",
    "        insert_df_into_db(conn, df_clients, \"clients\")\n",
    "            \n",
    "        print(\"\\nCreating the transaction_in table in the database...\")\n",
    "        create_table_transactions(conn, \"transactions_in\")\n",
    "\n",
    "        print(\"\\nInserting data into the table...\")\n",
    "        insert_df_into_db(conn, df_transactions_in, \"transactions_in\")\n",
    "    \n",
    "        print(\"\\nCreating the transaction_out table in the database...\")\n",
    "        create_table_transactions(conn, \"transactions_out\")\n",
    "\n",
    "        print(\"\\nInserting data into the table...\")\n",
    "        insert_df_into_db(conn, df_transactions_out, \"transactions_out\")\n",
    "       \n",
    "    print(\"\\n\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Transactions in\")\n",
    "    df_transactions_in.show()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Transactions out\")\n",
    "    df_transactions_out.show()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Clients\")\n",
    "    df_clients.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"The following error occurred: {e}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
